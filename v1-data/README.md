# v1-data

The v1-data subdirectory:

```
https://github.com/arcetri/verified-prime
```

contains information about a survey of __v(1)__ values used in primality proofs
for a large set of integers.
Details on this survey may be found in:

```
https://github.com/arcetri/verified-prime/v1-data/README.md
```

## Motivation

The v1-data subdirectory was created to support finding an optimal strategy for
testing if a large integers of the form __h*2<sup>n</sup>-1__ are prime.

We present a survey of __v(1)__ values that may be used to test of
__h*2<sup>n</sup>-1__ is prime.

## Our set pairs of large integers

We processed pairs of sets of 1000000 large integers of the form __h*2<sup>n</sup>-1__,
one of the pair is for when __h == 0 mod 3__ and the
other of the pair is for when __h != 0 mod 3__.

There are 8 set pairs, 7 are integers of the form __h*2<sup>n</sup>-1__
where __h__ and __n__ cover a range of large integers.
These 7 sets contain both primes and non-primes.
The 8th set pair only contains verified primes of the form __h*2<sup>n</sup>-1__.
For more information about those verified primes, see:

```
https://github.com/arcetri/verified-prime
```


Each of the 7 sets starts is an initial __n__ called __base_n__.
We used for follow 7 values of __base_n__:

```
4194304
4331116
4885002
5209020
6286862
7676777
8388608
```

The 1st __base_n__ is 2^22, and the last __base_n__ is 2^23.
The other __base_n__ values were generated by a pseudo-random
number generator between the 1st and last values.

Each of the 7 sets starts is an initial __h__ value called __base_h__.
The __base_h__ value is __base_h__ = 3 * __base_n__.

We excluded __h < 3n__ in order increase the of number of values in these sets that are prime.

NOTE: The 8th verified prime sets do not have the above constraints on __h__ and __n__.

Each set contains 1000000 large integers of the form __h*2<sup>n</sup>-1__.
As previously noted, one pair contains 1000000 large integers where __h == 0 mod 3__ and the
other pair contains 1000000 large integers where __h != 0 mod 3__.

We compiled reach of 1000000 large integers of the form __h*2<sup>n</sup>-1__,
having the following 2 properties: h is odd, and
__h*2<sup>n</sup>-1__ is not a multiple of 3.

## Job sub-directories

Data for the 7 sets of 1000000 large integers where __h == 0 mod 3__
is found in sub-directories of the form:

```
job.h-0mod3.n-digits
```

where __digits__ is one of the above mentioned __base_n__ values.

Data for the 7 sets of 1000000 large integers where __h != 0 mod 3__
is found in job sub-directories of the form:

```
job.h-not0mod3.n-digits
```

where __digits__ is one of the above mentioned __base_n__ values.

The 8th verified prime sets are found in these two sub-directories:

```
job.h-0mod3.prime
```
and
```
job.h-not0mod3.prime
```.

The above mentioned job sub-directories contain several types of files:

* jacobi string files
* list-h-n files
* sbatch SLURM jobs
* time files
* stderr files
* run all file
* tally analysis files

What follows in the rest of this section
are detailed descriptions of those file types.

### jacobi string files

Jacobi string files are found in files of the form:

```
jacobi.xyzzy
```

where __xyzzy__ is a 5 letter string.

All string files contain lines of the form:

```
h n jacobi-string
```

Where __h__ and __n__ are base 10 digits for a Riesel number
of the form __h*2<sup>n</sup>-1__.
There is a single space separating __h__, __n__, and the __jacobi-string__.

The __jacobi-string__ is a string containing +'s, -'s and 0's.
The characters in in the __jacobi-string__ represent values of the the
Jacobi symbol J(__X__, __h*2<sup>n</sup>-1__).
The first character in the __jacobi-string__ is for __X = 1__.
The 2nd character in the __jacobi-string__ is for __X = 2__, and so on.

Jacobi symbols J(a,b) may take on one of 2 values: 1, -1, or 0.

* If J(__X__, __h*2<sup>n</sup>-1__) == 1, then a '+' character is used
* If J(__X__, __h*2<sup>n</sup>-1__) == -1, then a '+' character is used
* If J(__X__, __h*2<sup>n</sup>-1__) == 0, then a '0' character is used

The __h__, __n__, and __jacobi-string__ values were generated by the
calc script:

```
jacobi-h-n.calc list-h-n.xyzzy 167
```

where __xyzzy__ is the same 5 letter string from the Jacobi string filename.

A jacobi string file contains up to 1000 lines.
For sets covering 1000000 large integers,
there are 1000  jacobi string files from jacobi.aaaaa through jacobi.aabml.

The __jacobi-string__ are all 167 characters long representing the Jacobi symbol
values from J(1, __h*2<sup>n</sup>-1__) to J(167, __h*2<sup>n</sup>-1__).
This range permits one to determine of __v(1)__ is valid for testing the
primality of __h*2<sup>n</sup>-1__ for 3 <= __v(1)__ <= 165.

For more information on calc see:

```
https://github.com/calc
```

### list-h-n files

The __h__ and __n__ values used by a given job set to determine
the set of __h*2<sup>n</sup>-1__ covered by the set.
The list-h-n files are filenames of the form:

```
list-h-n.xyzzy
```

where __xyzzy__ is the same 5 letter string from the Jacobi string filename.

A list-h-n file contains up to 1000 lines.
For sets covering 1000000 large integers,
there are 1000 list-h-n files from list-h-n.aaaaa through list-h-n.aabml.

The list-h-n files were generated by the calc scripts:

* h0mod3-n.calc
* hnot0mod3-n.calc

For the job sub-directories that correspond to __h == 0 mod 3__
and __h != 0 mod 3__ respectively.

### sbatch SLURM jobs

The computational work to generate of the jacobi string files
for each job set was performed with a set of SLURM jobs.
The sbatch SLURM job filenames are of the form:

```
sbatch.xyzzy.slurm
```

where __xyzzy__ is the same 5 letter string from the Jacobi string filename.

A SLURM job is also a bash shell script.
Sites that do not use SLURM can simply execute each
sbatch SLURM job as if it were a shell script.

For sets covering 1000000 large integers,
there are 1000 sbatch SLURM job files from sbatch.aaaaa.slurm
through sbatch.aabml.slurm.

### time files

The resources consumed to run each sbatch SLURM job is recorded
in a tile file.
The time file filenames are of the form:

```
time.xyzzy
```

where __xyzzy__ is the same 5 letter string from the Jacobi string filename.

For sets covering 1000000 large integers,
there are 1000 time files from time.aaaaa through time.aabml.

### stderr files

All errors and messages to stderr for a SLURM job are written to
a stderr file.
The stderr file filenames are of the form:

```
stderr.xyzzy
```

where __xyzzy__ is the same 5 letter string from the Jacobi string filename.

For sets covering 1000000 large integers,
there are 1000 stderr files from stderr.aaaaa through stderr.aabml.

Because all jobs completed without error, all stderr files are empty files.

### run all file

Each job sub-directory contains a singe file of the form:

```
run.all.sh
```

This is a shell script that will use the sbatch SLURM command
to schedule all of the SLURM jobs for the given job sub-directory.
Sites without SLURM may ignore the run all file and just
execute the sbatch SLURM files as if they were bash shell scripts.

### tally analysis files

The important results from a job sub-directory are summarized
in one of several tally analysis files:

* tally.1stint
* tally.1stodd
* tally.byfreq
* tally.byoddfreq
* tally.byodduse
* tally.byoddv1
* tally.byuse
* tally.byv1
* tally.int
* tally.odd

These tally analysis files were generated by jacobi-gentally
program via one of the following shell scripts:

* jacobi.tally.sh
* jacobi.prime.sh
* jacobi.jobset.sh

The above 3 shell scripts generate both pairs of job sub-directories.
I.e. These shell scripts generate both the job.h-0mod3.X and
the job.h-not0mod3.X job sub-directories.

The jacobi.tally.sh was used to generate the tally files for the 7
1000000 large integer pair job sub-directories.
The jacobi.prime.sh was used to generate the tally files for the
verified prime job sub-directories.
The jacobi.jobset.sh was used to generate the Summary data set
tally analysis files.

The entire set of job sub-directories, and the above 3 shell scripts
were launched from the shell script:

* jacobi.all.sh

Each of the tally analysis files, and the format of a tally analysis file
are described in a later section of this document.

## Summary data sets

There are two summary data sets, each of which contain just the
analysis of all job sub-directories:

* job.h-0mod3.jobset
* job.h-not0mod3.jobset

These two summary data sets contain only tally analysis files
because their data (in particular, the jacobi files) came
from the other job directories.
